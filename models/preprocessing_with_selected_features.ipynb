{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Modules and Checking Directory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.1.5'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/Livi/Projects/Black_mental_health/models'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/interim/features_and_target2_pre_get_dummies.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['number_of_hcpcs', 'number_of_services', 'total_beneficiaries',\n",
       "       'total_submitted_charges', 'avg_beneficiary_age', 'avg_hcc_risk_score',\n",
       "       'submitted_charges_per_person', 'services_per_person',\n",
       "       'submitted_charges_per_service', 'total_pop',\n",
       "       ...\n",
       "       'subregion_Pacific', 'subregion_South Atlantic',\n",
       "       'subregion_West North Central', 'subregion_West South Central',\n",
       "       'majority_asian', 'majority_black', 'majority_hispanic',\n",
       "       'majority_native_amer', 'majority_white', 'no_majority'],\n",
       "      dtype='object', length=188)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['payrate_level']\n",
    "X = pd.get_dummies(df.drop(columns='payrate_level'))\n",
    "\n",
    "X.columns = X.columns.str.replace('majority_majority_', 'majority_').str.replace('majority_no_', 'no_')\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling ONLY CONTINUOUS columns using PowerTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time scaled: 0.5751500129699707 minutes.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PowerTransformer\n",
    "import time\n",
    "\n",
    "start= time.time()\n",
    "\n",
    "scaler = PowerTransformer()\n",
    "\n",
    "X_scaled=X.copy()\n",
    "\n",
    "for col in X.columns:\n",
    "    if col =='entity_code_I':\n",
    "        break\n",
    "    else:\n",
    "        scaler.fit(np.array(X_scaled[col]).reshape(-1,1))\n",
    "        i_scaled = scaler.transform(np.array(X_scaled[col]).reshape(-1,1))\n",
    "        X_scaled[col] = i_scaled\n",
    "        \n",
    "        \n",
    "end= time.time()\n",
    "\n",
    "print('Time scaled:', (end-start)/60, 'minutes.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number_of_hcpcs</th>\n",
       "      <th>number_of_services</th>\n",
       "      <th>total_beneficiaries</th>\n",
       "      <th>total_submitted_charges</th>\n",
       "      <th>avg_beneficiary_age</th>\n",
       "      <th>avg_hcc_risk_score</th>\n",
       "      <th>submitted_charges_per_person</th>\n",
       "      <th>services_per_person</th>\n",
       "      <th>submitted_charges_per_service</th>\n",
       "      <th>total_pop</th>\n",
       "      <th>...</th>\n",
       "      <th>subregion_Pacific</th>\n",
       "      <th>subregion_South Atlantic</th>\n",
       "      <th>subregion_West North Central</th>\n",
       "      <th>subregion_West South Central</th>\n",
       "      <th>majority_asian</th>\n",
       "      <th>majority_black</th>\n",
       "      <th>majority_hispanic</th>\n",
       "      <th>majority_native_amer</th>\n",
       "      <th>majority_white</th>\n",
       "      <th>no_majority</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.003948</td>\n",
       "      <td>0.540055</td>\n",
       "      <td>0.851671</td>\n",
       "      <td>1.196155</td>\n",
       "      <td>0.998501</td>\n",
       "      <td>1.105662</td>\n",
       "      <td>0.871076</td>\n",
       "      <td>-0.119979</td>\n",
       "      <td>1.063762</td>\n",
       "      <td>0.781846</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.170174</td>\n",
       "      <td>0.576787</td>\n",
       "      <td>1.015528</td>\n",
       "      <td>0.573919</td>\n",
       "      <td>2.139463</td>\n",
       "      <td>0.994263</td>\n",
       "      <td>-0.276118</td>\n",
       "      <td>-0.317600</td>\n",
       "      <td>0.179416</td>\n",
       "      <td>-0.074416</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.402499</td>\n",
       "      <td>-1.478753</td>\n",
       "      <td>-2.032970</td>\n",
       "      <td>-2.079729</td>\n",
       "      <td>-1.181247</td>\n",
       "      <td>-1.398919</td>\n",
       "      <td>-1.041626</td>\n",
       "      <td>0.565058</td>\n",
       "      <td>-1.326987</td>\n",
       "      <td>-0.413310</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.447350</td>\n",
       "      <td>1.158778</td>\n",
       "      <td>1.311877</td>\n",
       "      <td>1.152199</td>\n",
       "      <td>1.833739</td>\n",
       "      <td>-0.416924</td>\n",
       "      <td>0.242840</td>\n",
       "      <td>0.442297</td>\n",
       "      <td>0.106138</td>\n",
       "      <td>0.795532</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.139490</td>\n",
       "      <td>-0.443103</td>\n",
       "      <td>-0.613947</td>\n",
       "      <td>-0.657554</td>\n",
       "      <td>-0.706375</td>\n",
       "      <td>1.649911</td>\n",
       "      <td>-0.268393</td>\n",
       "      <td>0.241994</td>\n",
       "      <td>-0.223406</td>\n",
       "      <td>-0.679061</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 188 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   number_of_hcpcs  number_of_services  total_beneficiaries  \\\n",
       "0        -0.003948            0.540055             0.851671   \n",
       "1        -0.170174            0.576787             1.015528   \n",
       "2        -1.402499           -1.478753            -2.032970   \n",
       "3         0.447350            1.158778             1.311877   \n",
       "4         0.139490           -0.443103            -0.613947   \n",
       "\n",
       "   total_submitted_charges  avg_beneficiary_age  avg_hcc_risk_score  \\\n",
       "0                 1.196155             0.998501            1.105662   \n",
       "1                 0.573919             2.139463            0.994263   \n",
       "2                -2.079729            -1.181247           -1.398919   \n",
       "3                 1.152199             1.833739           -0.416924   \n",
       "4                -0.657554            -0.706375            1.649911   \n",
       "\n",
       "   submitted_charges_per_person  services_per_person  \\\n",
       "0                      0.871076            -0.119979   \n",
       "1                     -0.276118            -0.317600   \n",
       "2                     -1.041626             0.565058   \n",
       "3                      0.242840             0.442297   \n",
       "4                     -0.268393             0.241994   \n",
       "\n",
       "   submitted_charges_per_service  total_pop  ...  subregion_Pacific  \\\n",
       "0                       1.063762   0.781846  ...                  0   \n",
       "1                       0.179416  -0.074416  ...                  0   \n",
       "2                      -1.326987  -0.413310  ...                  0   \n",
       "3                       0.106138   0.795532  ...                  0   \n",
       "4                      -0.223406  -0.679061  ...                  0   \n",
       "\n",
       "   subregion_South Atlantic  subregion_West North Central  \\\n",
       "0                         1                             0   \n",
       "1                         1                             0   \n",
       "2                         1                             0   \n",
       "3                         1                             0   \n",
       "4                         1                             0   \n",
       "\n",
       "   subregion_West South Central  majority_asian  majority_black  \\\n",
       "0                             0               0               0   \n",
       "1                             0               0               0   \n",
       "2                             0               0               1   \n",
       "3                             0               0               0   \n",
       "4                             0               0               0   \n",
       "\n",
       "   majority_hispanic  majority_native_amer  majority_white  no_majority  \n",
       "0                  0                     0               1            0  \n",
       "1                  0                     0               1            0  \n",
       "2                  0                     0               0            0  \n",
       "3                  0                     0               0            1  \n",
       "4                  0                     0               0            1  \n",
       "\n",
       "[5 rows x 188 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CV: Half Scaled and ONLY Selected Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>provider_type_Registered Dietitian or Nutrition Professional</th>\n",
       "      <td>0.090226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           0\n",
       "provider_type_Registered Dietitian or Nutrition...  0.090226"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_feats = pd.read_csv('../data/interim/ridge_features.csv',index_col=0)\n",
    "kbest_feats = pd.read_csv('../data/interim/kbest_features.csv', index_col=0)\n",
    "ridge_feats.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>provider_type_Mass Immunizer Roster Biller</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            0\n",
       "0  provider_type_Mass Immunizer Roster Biller"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kbest_feats.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_feats = list(ridge_feats.reset_index()['index'])\n",
    "kbest_feats = list(kbest_feats['0'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K Best Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV F1 Score RF: [0.52296647 0.51856622 0.52146914 0.52428817 0.52079646]\n",
      "Time: 0.4059203664461772 minutes\n",
      "CV F1 Scores GBC: [0.52880339 0.52122645 0.53637345 0.52749809 0.53274528]\n",
      "Time: 0.2726573665936788 minutes\n",
      "CV F1 Scores LR: [0.52880339 0.52122645 0.5347799  0.52749809 0.53139514]\n",
      "Time: 0.057468048731486004\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled[kbest_feats], y, test_size = 0.2, random_state=42)\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "scorer = make_scorer(f1_score, average = 'weighted')\n",
    "rf_cv3 = cross_val_score(rf, X_train[:100000], y_train[:100000], cv=5, scoring=scorer)\n",
    "\n",
    "end= time.time()\n",
    "total = end - start\n",
    "\n",
    "print('CV F1 Score RF:', rf_cv3)\n",
    "print(\"Time:\", total/60, \"minutes\")\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "gbc = GradientBoostingClassifier()\n",
    "scorer = make_scorer(f1_score, average = 'weighted')\n",
    "cv_scores_gbc3= cross_val_score(gbc,X_train[:10000],y_train[:10000],cv=5,scoring=scorer)\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print ('CV F1 Scores GBC:', cv_scores_gbc3)\n",
    "print('Time:', (end-start)/60, 'minutes')\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "start= time.time()\n",
    "\n",
    "lr = LogisticRegression(max_iter=500)\n",
    "scorer = make_scorer(f1_score, average = 'weighted')\n",
    "cv_scores_lr3 = cross_val_score(lr,X_train[:10000],y_train[:10000],cv=5,scoring=scorer)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print ('CV F1 Scores LR:', cv_scores_lr3)\n",
    "print('Time:', (end-start)/60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV F1 Score RF: [0.47419517 0.4743125  0.47322537 0.47880334 0.47434894]\n",
      "Time: 1.5162093838055928 minutes\n",
      "CV F1 Scores GBC: [0.46267757 0.47684456 0.46017945 0.47206531 0.46309023]\n",
      "Time: 0.3053579847017924 minutes\n",
      "CV F1 Scores LR: [0.46883799 0.47710803 0.46632294 0.47379844 0.46578955]\n",
      "Time: 0.04967144727706909\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled[ridge_feats], y, test_size = 0.2, random_state=42)\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "scorer = make_scorer(f1_score, average = 'weighted')\n",
    "rf_cv4 = cross_val_score(rf, X_train[:100000], y_train[:100000], cv=5, scoring=scorer)\n",
    "\n",
    "end= time.time()\n",
    "total = end - start\n",
    "\n",
    "print('CV F1 Score RF:', rf_cv4)\n",
    "print(\"Time:\", total/60, \"minutes\")\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "gbc = GradientBoostingClassifier()\n",
    "scorer = make_scorer(f1_score, average = 'weighted')\n",
    "cv_scores_gbc4= cross_val_score(gbc,X_train[:10000],y_train[:10000],cv=5,scoring=scorer)\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print ('CV F1 Scores GBC:', cv_scores_gbc4)\n",
    "print('Time:', (end-start)/60, 'minutes')\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "start= time.time()\n",
    "\n",
    "lr = LogisticRegression(max_iter=500)\n",
    "scorer = make_scorer(f1_score, average = 'weighted')\n",
    "cv_scores_lr4 = cross_val_score(lr,X_train[:10000],y_train[:10000],cv=5,scoring=scorer)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print ('CV F1 Scores LR:', cv_scores_lr4)\n",
    "print('Time:', (end-start)/60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Doing CV again, but WITH SCALING the binary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "start= time.time()\n",
    "\n",
    "scaler = PowerTransformer()\n",
    "scaler.fit(X)\n",
    "X_scaled2 = scaler.transform(X)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled2, y, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 5.403771114349365 minutes\n"
     ]
    }
   ],
   "source": [
    "end = time.time()\n",
    "print('time:', (end-start)/60, 'minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number_of_hcpcs</th>\n",
       "      <th>number_of_services</th>\n",
       "      <th>total_submitted_charges</th>\n",
       "      <th>avg_beneficiary_age</th>\n",
       "      <th>avg_hcc_risk_score</th>\n",
       "      <th>submitted_charges_per_person</th>\n",
       "      <th>services_per_person</th>\n",
       "      <th>submitted_charges_per_service</th>\n",
       "      <th>total_pop</th>\n",
       "      <th>percent_black</th>\n",
       "      <th>...</th>\n",
       "      <th>subregion_Pacific</th>\n",
       "      <th>subregion_South Atlantic</th>\n",
       "      <th>subregion_West North Central</th>\n",
       "      <th>subregion_West South Central</th>\n",
       "      <th>majority_asian</th>\n",
       "      <th>majority_black</th>\n",
       "      <th>majority_hispanic</th>\n",
       "      <th>majority_native_amer</th>\n",
       "      <th>majority_white</th>\n",
       "      <th>no_majority</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.003948</td>\n",
       "      <td>0.540055</td>\n",
       "      <td>1.196155</td>\n",
       "      <td>0.998501</td>\n",
       "      <td>1.105662</td>\n",
       "      <td>0.871076</td>\n",
       "      <td>-0.119979</td>\n",
       "      <td>1.063762</td>\n",
       "      <td>0.781846</td>\n",
       "      <td>0.413996</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.378901</td>\n",
       "      <td>2.036056</td>\n",
       "      <td>-0.285347</td>\n",
       "      <td>-0.331112</td>\n",
       "      <td>-0.0744</td>\n",
       "      <td>-0.225179</td>\n",
       "      <td>-0.234267</td>\n",
       "      <td>-0.033669</td>\n",
       "      <td>0.585053</td>\n",
       "      <td>-0.416918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 187 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   number_of_hcpcs  number_of_services  total_submitted_charges  \\\n",
       "0        -0.003948            0.540055                 1.196155   \n",
       "\n",
       "   avg_beneficiary_age  avg_hcc_risk_score  submitted_charges_per_person  \\\n",
       "0             0.998501            1.105662                      0.871076   \n",
       "\n",
       "   services_per_person  submitted_charges_per_service  total_pop  \\\n",
       "0            -0.119979                       1.063762   0.781846   \n",
       "\n",
       "   percent_black  ...  subregion_Pacific  subregion_South Atlantic  \\\n",
       "0       0.413996  ...          -0.378901                  2.036056   \n",
       "\n",
       "   subregion_West North Central  subregion_West South Central  majority_asian  \\\n",
       "0                     -0.285347                     -0.331112         -0.0744   \n",
       "\n",
       "   majority_black  majority_hispanic  majority_native_amer  majority_white  \\\n",
       "0       -0.225179          -0.234267             -0.033669        0.585053   \n",
       "\n",
       "   no_majority  \n",
       "0    -0.416918  \n",
       "\n",
       "[1 rows x 187 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_scaled2, columns = X.columns).head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kbest Feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV F1 Score RF: [0.52296647 0.51856622 0.52146914 0.52428817 0.52079646]\n",
      "Time: 0.3692087690035502 minutes\n",
      "CV F1 Scores GBC: [0.52296647 0.51856622 0.52146914 0.52428817 0.52079646]\n",
      "Time: 2.4240289171536764 minutes\n",
      "CV F1 Scores LR: [0.52296647 0.51856622 0.52146914 0.52428817 0.52079646]\n",
      "Time: 0.496477480729421\n"
     ]
    }
   ],
   "source": [
    "X_scaled2 = pd.DataFrame(X_scaled2, columns = X.columns)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled2[kbest_feats], y, test_size = 0.2, random_state=42)\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "scorer = make_scorer(f1_score, average = 'weighted')\n",
    "rf_cv5 = cross_val_score(rf, X_train[:100000], y_train[:100000], cv=5, scoring=scorer)\n",
    "\n",
    "end= time.time()\n",
    "total = end - start\n",
    "\n",
    "print('CV F1 Score RF:', rf_cv5)\n",
    "print(\"Time:\", total/60, \"minutes\")\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "gbc = GradientBoostingClassifier()\n",
    "scorer = make_scorer(f1_score, average = 'weighted')\n",
    "cv_scores_gbc5= cross_val_score(gbc,X_train[:100000],y_train[:100000],cv=5,scoring=scorer)\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print ('CV F1 Scores GBC:', cv_scores_gbc5)\n",
    "print('Time:', (end-start)/60, 'minutes')\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "start= time.time()\n",
    "\n",
    "lr = LogisticRegression(max_iter=500)\n",
    "scorer = make_scorer(f1_score, average = 'weighted')\n",
    "cv_scores_lr5 = cross_val_score(lr,X_train[:100000],y_train[:100000],cv=5,scoring=scorer)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print ('CV F1 Scores LR:', cv_scores_lr5)\n",
    "print('Time:', (end-start)/60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge Feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV F1 Score RF: [0.47415974 0.47218686 0.47362479 0.47915108 0.47354599]\n",
      "Time: 1.3058063507080078 minutes\n",
      "CV F1 Scores GBC: [0.4604279  0.45706118 0.4599994  0.46110714 0.45985048]\n",
      "Time: 3.534658714135488 minutes\n",
      "CV F1 Scores LR: [0.46035023 0.45715765 0.46022398 0.46136849 0.45938331]\n",
      "Time: 0.4018767992655436\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled2[ridge_feats], y, test_size = 0.2, random_state=42)\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "scorer = make_scorer(f1_score, average = 'weighted')\n",
    "rf_cv6 = cross_val_score(rf, X_train[:100000], y_train[:100000], cv=5, scoring=scorer)\n",
    "\n",
    "end= time.time()\n",
    "total = end - start\n",
    "\n",
    "print('CV F1 Score RF:', rf_cv6)\n",
    "print(\"Time:\", total/60, \"minutes\")\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "gbc = GradientBoostingClassifier()\n",
    "scorer = make_scorer(f1_score, average = 'weighted')\n",
    "cv_scores_gbc6= cross_val_score(gbc,X_train[:100000],y_train[:100000],cv=5,scoring=scorer)\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print ('CV F1 Scores GBC:', cv_scores_gbc6)\n",
    "print('Time:', (end-start)/60, 'minutes')\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "start= time.time()\n",
    "\n",
    "lr = LogisticRegression(max_iter=500)\n",
    "scorer = make_scorer(f1_score, average = 'weighted')\n",
    "cv_scores_lr6 = cross_val_score(lr,X_train[:100000],y_train[:100000],cv=5,scoring=scorer)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print ('CV F1 Scores LR:', cv_scores_lr6)\n",
    "print('Time:', (end-start)/60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>models</th>\n",
       "      <th>CV: Scale1, all feats</th>\n",
       "      <th>CV: Scale1, kbest</th>\n",
       "      <th>CV: Scale1, ridge feats</th>\n",
       "      <th>CV: Scale2, all feats</th>\n",
       "      <th>CV: Scale2, kbest feats</th>\n",
       "      <th>CV: Scale2, ridge feats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.590946</td>\n",
       "      <td>0.530178</td>\n",
       "      <td>0.474977</td>\n",
       "      <td>0.591320</td>\n",
       "      <td>0.521617</td>\n",
       "      <td>0.474534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.606442</td>\n",
       "      <td>0.529329</td>\n",
       "      <td>0.466971</td>\n",
       "      <td>0.606779</td>\n",
       "      <td>0.521617</td>\n",
       "      <td>0.459689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.596830</td>\n",
       "      <td>0.528741</td>\n",
       "      <td>0.470371</td>\n",
       "      <td>0.596491</td>\n",
       "      <td>0.521617</td>\n",
       "      <td>0.459697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                models  CV: Scale1, all feats  CV: Scale1, kbest  \\\n",
       "0        Random Forest               0.590946           0.530178   \n",
       "1    Gradient Boosting               0.606442           0.529329   \n",
       "2  Logistic Regression               0.596830           0.528741   \n",
       "\n",
       "   CV: Scale1, ridge feats  CV: Scale2, all feats  CV: Scale2, kbest feats  \\\n",
       "0                 0.474977               0.591320                 0.521617   \n",
       "1                 0.466971               0.606779                 0.521617   \n",
       "2                 0.470371               0.596491                 0.521617   \n",
       "\n",
       "   CV: Scale2, ridge feats  \n",
       "0                 0.474534  \n",
       "1                 0.459689  \n",
       "2                 0.459697  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_metrics = pd.DataFrame({'models':['Random Forest','Gradient Boosting','Logistic Regression'],\n",
    "             'CV: Scale1, kbest' : [rf_cv3.mean(), cv_scores_gbc3.mean(), cv_scores_lr3.mean()], \n",
    "            'CV: Scale1, ridge feats' : [rf_cv4.mean(), cv_scores_gbc4.mean(), cv_scores_lr4.mean()], \n",
    "             'CV: Scale2, kbest feats' : [rf_cv5.mean(), cv_scores_gbc5.mean(), cv_scores_lr5.mean()],\n",
    "            'CV: Scale2, ridge feats' : [rf_cv6.mean(), cv_scores_gbc6.mean(), cv_scores_lr6.mean()], \n",
    "             })\n",
    "\n",
    "cv_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    If I do limit the features, I may want to use KBest features rather than Ridge features, because they scored much better. The models with limited features performed much worse than the ones with all features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

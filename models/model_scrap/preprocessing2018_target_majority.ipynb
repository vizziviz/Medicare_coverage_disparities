{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Modules and Checking Directory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.1.5'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/Livi/Projects/Black_mental_health/models'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Livi/opt/anaconda3/envs/springboard/lib/python3.7/site-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "original_med = pd.read_csv('../data/processed/medicare18.csv', dtype={'full_zip':'object', 'npi':'object'}, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1115360 entries, 0 to 1115359\n",
      "Data columns (total 24 columns):\n",
      " #   Column                               Non-Null Count    Dtype  \n",
      "---  ------                               --------------    -----  \n",
      " 0   npi                                  1115360 non-null  object \n",
      " 1   entity_code                          1115360 non-null  object \n",
      " 2   full_zip                             1115360 non-null  object \n",
      " 3   state                                1115360 non-null  object \n",
      " 4   country                              1115360 non-null  object \n",
      " 5   provider_type                        1115360 non-null  object \n",
      " 6   medicare_participation_indicator     1115360 non-null  object \n",
      " 7   number_of_hcpcs                      1115360 non-null  int64  \n",
      " 8   number_of_services                   1115360 non-null  float64\n",
      " 9   total_beneficiaries                  1115360 non-null  int64  \n",
      " 10  total_submitted_charges              1115360 non-null  float64\n",
      " 11  total_allowed_payment                1115360 non-null  float64\n",
      " 12  total_medicare_payment               1115360 non-null  float64\n",
      " 13  total_medicare_standardized_payment  1115360 non-null  float64\n",
      " 14  avg_beneficiary_age                  1115360 non-null  int64  \n",
      " 15  avg_hcc_risk_score                   1115360 non-null  float64\n",
      " 16  medicare_payment_per_person          1115360 non-null  float64\n",
      " 17  submitted_charges_per_person         1115360 non-null  float64\n",
      " 18  services_per_person                  1115360 non-null  float64\n",
      " 19  submitted_charges_per_service        1115360 non-null  float64\n",
      " 20  medicare_payment_per_service         1115360 non-null  float64\n",
      " 21  percentage_rate                      1115360 non-null  float64\n",
      " 22  region                               1115360 non-null  object \n",
      " 23  subregion                            1115360 non-null  object \n",
      "dtypes: float64(12), int64(3), object(9)\n",
      "memory usage: 212.7+ MB\n"
     ]
    }
   ],
   "source": [
    "original_med.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1115360, 24)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_med.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "census = pd.read_csv('../data/processed/2018pops.csv', index_col = 0, dtype={'geo_id':'str'}, parse_dates=['do_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 32799 entries, 0 to 33119\n",
      "Data columns (total 18 columns):\n",
      " #   Column                     Non-Null Count  Dtype         \n",
      "---  ------                     --------------  -----         \n",
      " 0   geo_id                     32799 non-null  object        \n",
      " 1   total_pop                  32799 non-null  int64         \n",
      " 2   white_pop                  32799 non-null  int64         \n",
      " 3   black_pop                  32799 non-null  int64         \n",
      " 4   asian_pop                  32799 non-null  int64         \n",
      " 5   hispanic_pop               32799 non-null  int64         \n",
      " 6   amerindian_pop             32799 non-null  int64         \n",
      " 7   other_race_pop             32799 non-null  int64         \n",
      " 8   two_or_more_races_pop      32799 non-null  int64         \n",
      " 9   do_date                    32799 non-null  datetime64[ns]\n",
      " 10  percent_black              32799 non-null  float64       \n",
      " 11  percent_white              32799 non-null  float64       \n",
      " 12  percent_native_amer        32799 non-null  float64       \n",
      " 13  percent_hispanic           32799 non-null  float64       \n",
      " 14  percent_other              32799 non-null  float64       \n",
      " 15  percent_asian              32799 non-null  float64       \n",
      " 16  percent_two_or_more_races  32799 non-null  float64       \n",
      " 17  majority                   32799 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(7), int64(8), object(2)\n",
      "memory usage: 4.8+ MB\n"
     ]
    }
   ],
   "source": [
    "census.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo_id</th>\n",
       "      <th>total_pop</th>\n",
       "      <th>percent_black</th>\n",
       "      <th>percent_white</th>\n",
       "      <th>percent_native_amer</th>\n",
       "      <th>percent_hispanic</th>\n",
       "      <th>percent_other</th>\n",
       "      <th>percent_asian</th>\n",
       "      <th>percent_two_or_more_races</th>\n",
       "      <th>majority</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33115</th>\n",
       "      <td>35463</td>\n",
       "      <td>1794</td>\n",
       "      <td>0.323857</td>\n",
       "      <td>0.676143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>majority_white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33116</th>\n",
       "      <td>77664</td>\n",
       "      <td>2667</td>\n",
       "      <td>0.079865</td>\n",
       "      <td>0.828271</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.069366</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009374</td>\n",
       "      <td>0.013123</td>\n",
       "      <td>majority_white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33117</th>\n",
       "      <td>21822</td>\n",
       "      <td>2013</td>\n",
       "      <td>0.169399</td>\n",
       "      <td>0.710879</td>\n",
       "      <td>0.017387</td>\n",
       "      <td>0.065574</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021361</td>\n",
       "      <td>0.015400</td>\n",
       "      <td>majority_white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33118</th>\n",
       "      <td>07418</td>\n",
       "      <td>2304</td>\n",
       "      <td>0.044271</td>\n",
       "      <td>0.904080</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043403</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008247</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>majority_white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33119</th>\n",
       "      <td>03036</td>\n",
       "      <td>5039</td>\n",
       "      <td>0.003969</td>\n",
       "      <td>0.936098</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027783</td>\n",
       "      <td>0.006152</td>\n",
       "      <td>0.022028</td>\n",
       "      <td>0.003969</td>\n",
       "      <td>majority_white</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      geo_id  total_pop  percent_black  percent_white  percent_native_amer  \\\n",
       "33115  35463       1794       0.323857       0.676143             0.000000   \n",
       "33116  77664       2667       0.079865       0.828271             0.000000   \n",
       "33117  21822       2013       0.169399       0.710879             0.017387   \n",
       "33118  07418       2304       0.044271       0.904080             0.000000   \n",
       "33119  03036       5039       0.003969       0.936098             0.000000   \n",
       "\n",
       "       percent_hispanic  percent_other  percent_asian  \\\n",
       "33115          0.000000       0.000000       0.000000   \n",
       "33116          0.069366       0.000000       0.009374   \n",
       "33117          0.065574       0.000000       0.021361   \n",
       "33118          0.043403       0.000000       0.008247   \n",
       "33119          0.027783       0.006152       0.022028   \n",
       "\n",
       "       percent_two_or_more_races        majority  \n",
       "33115                   0.000000  majority_white  \n",
       "33116                   0.013123  majority_white  \n",
       "33117                   0.015400  majority_white  \n",
       "33118                   0.000000  majority_white  \n",
       "33119                   0.003969  majority_white  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['geo_id', 'total_pop', 'percent_black', 'percent_white','percent_native_amer', \n",
    "        'percent_hispanic', 'percent_other','percent_asian', 'percent_two_or_more_races', 'majority']\n",
    "keep_only = census.loc[:, cols]\n",
    "keep_only.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5    1115360\n",
       " Name: full_zip, dtype: int64,\n",
       " 5    32799\n",
       " Name: geo_id, dtype: int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_med.full_zip.apply(len).value_counts(), census.geo_id.apply(len).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "med = pd.merge(original_med, keep_only, how='left', left_on='full_zip', right_on='geo_id').drop(columns = 'geo_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1115360, 24), (1115360, 33))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_med.shape, med.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>npi</th>\n",
       "      <th>entity_code</th>\n",
       "      <th>full_zip</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "      <th>provider_type</th>\n",
       "      <th>medicare_participation_indicator</th>\n",
       "      <th>number_of_hcpcs</th>\n",
       "      <th>number_of_services</th>\n",
       "      <th>total_beneficiaries</th>\n",
       "      <th>...</th>\n",
       "      <th>subregion</th>\n",
       "      <th>total_pop</th>\n",
       "      <th>percent_black</th>\n",
       "      <th>percent_white</th>\n",
       "      <th>percent_native_amer</th>\n",
       "      <th>percent_hispanic</th>\n",
       "      <th>percent_other</th>\n",
       "      <th>percent_asian</th>\n",
       "      <th>percent_two_or_more_races</th>\n",
       "      <th>majority</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1003000126</td>\n",
       "      <td>I</td>\n",
       "      <td>21502</td>\n",
       "      <td>MD</td>\n",
       "      <td>US</td>\n",
       "      <td>Internal Medicine</td>\n",
       "      <td>Y</td>\n",
       "      <td>19</td>\n",
       "      <td>1218.0</td>\n",
       "      <td>445</td>\n",
       "      <td>...</td>\n",
       "      <td>South Atlantic</td>\n",
       "      <td>42583.0</td>\n",
       "      <td>0.109645</td>\n",
       "      <td>0.839772</td>\n",
       "      <td>0.001573</td>\n",
       "      <td>0.018834</td>\n",
       "      <td>0.001127</td>\n",
       "      <td>0.007327</td>\n",
       "      <td>0.021464</td>\n",
       "      <td>majority_white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1003006586</td>\n",
       "      <td>I</td>\n",
       "      <td>20832</td>\n",
       "      <td>MD</td>\n",
       "      <td>US</td>\n",
       "      <td>Internal Medicine</td>\n",
       "      <td>Y</td>\n",
       "      <td>16</td>\n",
       "      <td>1293.0</td>\n",
       "      <td>546</td>\n",
       "      <td>...</td>\n",
       "      <td>South Atlantic</td>\n",
       "      <td>26448.0</td>\n",
       "      <td>0.108553</td>\n",
       "      <td>0.612523</td>\n",
       "      <td>0.003932</td>\n",
       "      <td>0.106360</td>\n",
       "      <td>0.006579</td>\n",
       "      <td>0.123299</td>\n",
       "      <td>0.038755</td>\n",
       "      <td>majority_white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1003006800</td>\n",
       "      <td>I</td>\n",
       "      <td>21202</td>\n",
       "      <td>MD</td>\n",
       "      <td>US</td>\n",
       "      <td>Physician Assistant</td>\n",
       "      <td>Y</td>\n",
       "      <td>4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>South Atlantic</td>\n",
       "      <td>21010.0</td>\n",
       "      <td>0.579819</td>\n",
       "      <td>0.303475</td>\n",
       "      <td>0.002237</td>\n",
       "      <td>0.042075</td>\n",
       "      <td>0.006140</td>\n",
       "      <td>0.045740</td>\n",
       "      <td>0.017753</td>\n",
       "      <td>majority_black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1003007816</td>\n",
       "      <td>I</td>\n",
       "      <td>20910</td>\n",
       "      <td>MD</td>\n",
       "      <td>US</td>\n",
       "      <td>Ophthalmology</td>\n",
       "      <td>Y</td>\n",
       "      <td>30</td>\n",
       "      <td>3417.0</td>\n",
       "      <td>791</td>\n",
       "      <td>...</td>\n",
       "      <td>South Atlantic</td>\n",
       "      <td>42868.0</td>\n",
       "      <td>0.309042</td>\n",
       "      <td>0.448306</td>\n",
       "      <td>0.002659</td>\n",
       "      <td>0.135416</td>\n",
       "      <td>0.004689</td>\n",
       "      <td>0.067883</td>\n",
       "      <td>0.031539</td>\n",
       "      <td>no_majority</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1003007824</td>\n",
       "      <td>I</td>\n",
       "      <td>21201</td>\n",
       "      <td>MD</td>\n",
       "      <td>US</td>\n",
       "      <td>Internal Medicine</td>\n",
       "      <td>Y</td>\n",
       "      <td>22</td>\n",
       "      <td>262.0</td>\n",
       "      <td>72</td>\n",
       "      <td>...</td>\n",
       "      <td>South Atlantic</td>\n",
       "      <td>17136.0</td>\n",
       "      <td>0.498833</td>\n",
       "      <td>0.337768</td>\n",
       "      <td>0.004260</td>\n",
       "      <td>0.039974</td>\n",
       "      <td>0.004785</td>\n",
       "      <td>0.079890</td>\n",
       "      <td>0.034022</td>\n",
       "      <td>no_majority</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          npi entity_code full_zip state country        provider_type  \\\n",
       "0  1003000126           I    21502    MD      US    Internal Medicine   \n",
       "1  1003006586           I    20832    MD      US    Internal Medicine   \n",
       "2  1003006800           I    21202    MD      US  Physician Assistant   \n",
       "3  1003007816           I    20910    MD      US        Ophthalmology   \n",
       "4  1003007824           I    21201    MD      US    Internal Medicine   \n",
       "\n",
       "  medicare_participation_indicator  number_of_hcpcs  number_of_services  \\\n",
       "0                                Y               19              1218.0   \n",
       "1                                Y               16              1293.0   \n",
       "2                                Y                4                58.0   \n",
       "3                                Y               30              3417.0   \n",
       "4                                Y               22               262.0   \n",
       "\n",
       "   total_beneficiaries  ...       subregion  total_pop  percent_black  \\\n",
       "0                  445  ...  South Atlantic    42583.0       0.109645   \n",
       "1                  546  ...  South Atlantic    26448.0       0.108553   \n",
       "2                   12  ...  South Atlantic    21010.0       0.579819   \n",
       "3                  791  ...  South Atlantic    42868.0       0.309042   \n",
       "4                   72  ...  South Atlantic    17136.0       0.498833   \n",
       "\n",
       "   percent_white  percent_native_amer  percent_hispanic  percent_other  \\\n",
       "0       0.839772             0.001573          0.018834       0.001127   \n",
       "1       0.612523             0.003932          0.106360       0.006579   \n",
       "2       0.303475             0.002237          0.042075       0.006140   \n",
       "3       0.448306             0.002659          0.135416       0.004689   \n",
       "4       0.337768             0.004260          0.039974       0.004785   \n",
       "\n",
       "   percent_asian  percent_two_or_more_races        majority  \n",
       "0       0.007327                   0.021464  majority_white  \n",
       "1       0.123299                   0.038755  majority_white  \n",
       "2       0.045740                   0.017753  majority_black  \n",
       "3       0.067883                   0.031539     no_majority  \n",
       "4       0.079890                   0.034022     no_majority  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "med.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1115360 entries, 0 to 1115359\n",
      "Data columns (total 33 columns):\n",
      " #   Column                               Non-Null Count    Dtype  \n",
      "---  ------                               --------------    -----  \n",
      " 0   npi                                  1115360 non-null  object \n",
      " 1   entity_code                          1115360 non-null  object \n",
      " 2   full_zip                             1115360 non-null  object \n",
      " 3   state                                1115360 non-null  object \n",
      " 4   country                              1115360 non-null  object \n",
      " 5   provider_type                        1115360 non-null  object \n",
      " 6   medicare_participation_indicator     1115360 non-null  object \n",
      " 7   number_of_hcpcs                      1115360 non-null  int64  \n",
      " 8   number_of_services                   1115360 non-null  float64\n",
      " 9   total_beneficiaries                  1115360 non-null  int64  \n",
      " 10  total_submitted_charges              1115360 non-null  float64\n",
      " 11  total_allowed_payment                1115360 non-null  float64\n",
      " 12  total_medicare_payment               1115360 non-null  float64\n",
      " 13  total_medicare_standardized_payment  1115360 non-null  float64\n",
      " 14  avg_beneficiary_age                  1115360 non-null  int64  \n",
      " 15  avg_hcc_risk_score                   1115360 non-null  float64\n",
      " 16  medicare_payment_per_person          1115360 non-null  float64\n",
      " 17  submitted_charges_per_person         1115360 non-null  float64\n",
      " 18  services_per_person                  1115360 non-null  float64\n",
      " 19  submitted_charges_per_service        1115360 non-null  float64\n",
      " 20  medicare_payment_per_service         1115360 non-null  float64\n",
      " 21  percentage_rate                      1115360 non-null  float64\n",
      " 22  region                               1115360 non-null  object \n",
      " 23  subregion                            1115360 non-null  object \n",
      " 24  total_pop                            1072142 non-null  float64\n",
      " 25  percent_black                        1072142 non-null  float64\n",
      " 26  percent_white                        1072142 non-null  float64\n",
      " 27  percent_native_amer                  1072142 non-null  float64\n",
      " 28  percent_hispanic                     1072142 non-null  float64\n",
      " 29  percent_other                        1072142 non-null  float64\n",
      " 30  percent_asian                        1072142 non-null  float64\n",
      " 31  percent_two_or_more_races            1072142 non-null  float64\n",
      " 32  majority                             1072142 non-null  object \n",
      "dtypes: float64(20), int64(3), object(10)\n",
      "memory usage: 289.3+ MB\n"
     ]
    }
   ],
   "source": [
    "med.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census.geo_id.isin(\n",
    "    med[med.total_pop.isnull()].full_zip\n",
    "        ).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There may be new zip codes in 2018 Medicare that the 2018 Census estimates don't know about. Removing these rows with missing Census info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1072142, 33)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = med[med.total_pop.isnull()].index\n",
    "med.drop(index = idx, inplace=True)\n",
    "med.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(med.columns[med.columns.str.contains('percent_')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['entity_code', 'state', 'provider_type',\n",
       "       'medicare_participation_indicator', 'number_of_hcpcs',\n",
       "       'number_of_services', 'total_beneficiaries', 'total_submitted_charges',\n",
       "       'total_allowed_payment', 'total_medicare_payment',\n",
       "       'total_medicare_standardized_payment', 'avg_beneficiary_age',\n",
       "       'avg_hcc_risk_score', 'medicare_payment_per_person',\n",
       "       'submitted_charges_per_person', 'services_per_person',\n",
       "       'submitted_charges_per_service', 'medicare_payment_per_service',\n",
       "       'percentage_rate', 'region', 'subregion', 'total_pop', 'majority'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = cols + ['npi','country', 'full_zip']\n",
    "df = med.drop(columns = cols)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['majority']\n",
    "X = pd.get_dummies(df.drop(columns=['majority']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling Using PowerTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Livi/opt/anaconda3/envs/springboard/lib/python3.7/site-packages/numpy/core/_methods.py:195: RuntimeWarning: overflow encountered in multiply\n",
      "  x = um.multiply(x, x, out=x)\n",
      "/Users/Livi/opt/anaconda3/envs/springboard/lib/python3.7/site-packages/numpy/core/_methods.py:199: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(x, axis, dtype, out, keepdims)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time scaled: 4.953314836819967 minutes.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PowerTransformer\n",
    "import time\n",
    "\n",
    "start= time.time()\n",
    "\n",
    "scaler = PowerTransformer()\n",
    "scaler.fit(X)\n",
    "X_scaled = scaler.transform(X)\n",
    "\n",
    "end= time.time()\n",
    "\n",
    "print('Time scaled:', (end-start)/60, 'minutes.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X[:100000], y[:100000], test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV F1 Score: [0.77255375 0.77618831 0.77550484 0.78176267 0.78018081]\n",
      "Time: 1.2829632997512816 minutes\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "\n",
    "rf = RandomForestClassifier(n_jobs=-1)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "scorer = make_scorer(f1_score, average = 'weighted')\n",
    "rf_cv = cross_val_score(rf, X_train, y_train, cv=5, scoring=scorer)\n",
    "\n",
    "end= time.time()\n",
    "total = end - start\n",
    "\n",
    "print('CV F1 Score:', rf_cv)\n",
    "print(\"Time:\", total/60, \"minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV F1 Scores: [0.91014245 0.91274777 0.90933813 0.90549287 0.90868697]\n",
      "Time: 9.293838036060333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "gbc = GradientBoostingClassifier()\n",
    "scorer = make_scorer(f1_score, average = 'weighted')\n",
    "cv_scores_gbc= cross_val_score(gbc,X_train,y_train,cv=5,scoring=scorer, n_jobs=-1)\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print ('CV F1 Scores:', cv_scores_gbc)\n",
    "print('Time:', (end-start)/60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV F1 Scores: [0.66157371 0.66085472 0.66015415 0.66156685 0.6603621 ]\n",
      "Time: 5.382922832171122\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "start=time.time()\n",
    "\n",
    "lr = LogisticRegression(n_jobs=-1)\n",
    "scorer = make_scorer(f1_score, average = 'weighted')\n",
    "cv_scores_lr = cross_val_score(lr,X_train,y_train,cv=5,scoring=scorer, n_jobs=-1)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print ('CV F1 Scores:', cv_scores_lr)\n",
    "print('Time:', (end-start)/60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "svc = SVC(kernel='linear')\n",
    "scorer = make_scorer(f1_score, average = 'weighted')\n",
    "svc_cv = cross_val_score(svc, X_train[:10000], y_train[:10000], cv=5, scoring = scorer, n_jobs=-1)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(svc_cv)\n",
    "print('Time:', (end-start)/60, 'minutes')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>models</th>\n",
       "      <th>Mean CV F1 Scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.777238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.909282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.660902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                models  Mean CV F1 Scores\n",
       "0        Random Forest           0.777238\n",
       "1    Gradient Boosting           0.909282\n",
       "2  Logistic Regression           0.660902"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'models':['Random Forest','Gradient Boosting','Logistic Regression'],\n",
    "             'Mean CV F1 Scores': [rf_cv.mean(), cv_scores_gbc.mean(), cv_scores_lr.mean()]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier()"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "total_pop                             0.846763\n",
       "avg_hcc_risk_score                    0.029371\n",
       "state_OH                              0.023922\n",
       "subregion_East North Central          0.017539\n",
       "region_South                          0.017092\n",
       "region_Midwest                        0.013137\n",
       "subregion_South Atlantic              0.011842\n",
       "avg_beneficiary_age                   0.011504\n",
       "state_MD                              0.008858\n",
       "state_IL                              0.008817\n",
       "submitted_charges_per_service         0.004132\n",
       "total_beneficiaries                   0.000892\n",
       "provider_type_Diagnostic Radiology    0.000883\n",
       "services_per_person                   0.000711\n",
       "provider_type_Centralized Flu         0.000698\n",
       "number_of_services                    0.000671\n",
       "provider_type_Internal Medicine       0.000485\n",
       "percentage_rate                       0.000464\n",
       "provider_type_Neurosurgery            0.000264\n",
       "provider_type_Nurse Practitioner      0.000245\n",
       "dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(gbc.feature_importances_, index = X.columns).sort_values(ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without any hyperparameter tuning my best model was the Logistic Regression with 90%. In another preprocessing notebook, the Logistic Regression model also performed best with addition Medicare-Payment columns (which I left out here because of possible collinearity) at 99%. \n",
    "\n",
    "Because the ratio of Medicare payment to Submitted charges actually tells whether the client is low rate, medium rate or high rate, I prefer to leave these out. I'm not sure if the models can \"figure out\" that relationship or not. \n",
    "\n",
    "My goal is actually to have a pretty good model that has a few mistakes because these mistakes are just as telling as the ability of the model to correctly identify classes. \n",
    "\n",
    "On that note, I am interested in the F1 Score particularly for the \"very high\" class and \"low\" class because I want to know whether the model falsely labels high-rate providers as low or vice versa. That said, maybe I don't want to optimize for \"low\" class F1 Score but rather the OVERALL F1 score. If a model is generally very accurate but still mislabels some outliers, those outliers may be worth re-examining. \n",
    "\n",
    "Overall, my modeling notebook will focus most heavily of feature importances and tables that contain the extreme outliers: low rate providers labeled as 'very high' and very high rate providers labeled as very low. I want to see if these providers show a pattern. \n",
    "\n",
    "If they do seem fishy, a final iteration of modeling may be one that labels these outliers as \"wrongly compensated\" and trains on the data to look for other potential \"wrongly compensated\" providers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I didn't scale my date before modeling here, both because I may want to say that for the \"modeling\" stage since my initial performances were good and because the combination of binary and continuous variables may complicate that process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "temp.to_csv('../data/processed/feature_matrix_scaled_PT.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
